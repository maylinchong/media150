<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reading 2</title>
</head> 
    <style>
        h1 {
            color: olive;
          }
            h2 {
                color: lightseagreen;
            }
    </style>

<body>
    <h1> Reading 2 </h1> 
         <h2> With 'AI slop' distorting our reality, the world is sleepwalking into disaster by Nesrine Malik
         </h2>
        <a href="index.html">Back to Home Page </a>
        <p> In With “AI slop” distorting our reality, the world is sleepwalking into disaster, Nesrine Malik argues that the overwhelming presence of AI-generated imagery is not just cluttering our feeds but actively reshaping how we perceive reality. What stood out to me most was her idea that we now live between two parallel visual channels: real images of the world and artificial ones designed to entertain, provoke, or manipulate. The danger, Malik suggests, is not simply that these images are fake, but that their sheer volume and emotional pull distort how we process what is real and urgent.
            One of the most unsettling parts of the essay is Malik's discussion of political AI imagery. AI slop does not just blur reality, it rewrites it by creating endless fictional scenarios that align with specific ideologies. These images feel powerful because they look believable and are easy to share, especially through platforms like WhatsApp where there is no public space for correction or debate. Malik's example of her elderly relative believing AI-generated images about Sudan shows how trust, technology, and emotion combine to make misinformation sticky. This made me think about how visual media has more authority than text. Seeing feels like knowing, even when what we see is completely fabricated.
            Malik's analysis of AI's “structural conservatism” also felt important. Because generative AI is trained on biased historical data, it often reproduces nostalgic and exclusionary visions of the past. The rise of AI-generated images that glorify submissive women, white families, or rigid gender roles shows how technology can reinforce harmful hierarchies under the guise of aesthetics or fantasy. What makes this especially dangerous is that these images are not presented as arguments, but as vibes. They do not demand critical thinking, only passive consumption.
            At the same time, Malik makes it clear that not all AI slop is ideological. Much of it exists simply to farm attention. Platforms benefit from cheap, endlessly generated content that keeps users scrolling, regardless of truth or quality. This constant exposure creates visual exhaustion. When images of real suffering exist alongside cartoonish memes and AI “eye balm,” everything starts to feel flattened. The result is a numbness where even the most serious events struggle to provoke meaningful response.
            Overall, Malik's essay made me reflect on how visual overload can lead to paralysis rather than awareness. We are not uninformed, but overwhelmed. When reality itself feels unstable, it becomes easier to disengage than to act. The idea of “sleepwalking into disaster” feels accurate because it describes a quiet erosion of attention and urgency. Malik's warning is not about technology alone, but about what happens when we stop trusting our eyes and stop questioning what we see.
            
        </p> 
    </body>
</html>